{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb289e07-a081-48e5-a5ff-8bddfe21db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: joblib in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\jupyterlab\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn numpy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752498c1-6922-4f4a-8bc4-8521c1a7dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded. Shape: (7032, 21)\n",
      "Features included: ['Contract', 'tenure', 'InternetService', 'MonthlyCharges', 'OnlineSecurity', 'TechSupport']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the file path\n",
    "DATA_PATH = \"Telco-Customer-Churn.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Initial data cleaning (TotalCharges is NOT used but still good practice)\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)\n",
    "df.dropna(subset=['TotalCharges'], inplace=True)\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "\n",
    "# ====================================================================\n",
    "# --- NEW: Define the EXACT six features required ---\n",
    "# ====================================================================\n",
    "REQUIRED_FEATURES = [\n",
    "    'Contract', \n",
    "    'tenure', \n",
    "    'InternetService', \n",
    "    'MonthlyCharges', \n",
    "    'OnlineSecurity', \n",
    "    'TechSupport'\n",
    "]\n",
    "TARGET_COLUMN = 'Churn'\n",
    "\n",
    "# Separate features (X) using only the required list, and target (y)\n",
    "X = df[REQUIRED_FEATURES]\n",
    "y = df[TARGET_COLUMN].apply(lambda x: 1 if x == 'Yes' else 0) # Convert 'Yes'/'No' to 1/0\n",
    "\n",
    "print(f\"Data Loaded. Shape: {df.shape}\")\n",
    "print(f\"Features included: {REQUIRED_FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7beda040-fdb3-498e-bca3-08c0d14ca79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded. Shape: (7032, 21)\n",
      "Features included: ['Contract', 'tenure', 'InternetService', 'MonthlyCharges', 'OnlineSecurity', 'TechSupport']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the file path\n",
    "DATA_PATH = \"Telco-Customer-Churn.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Initial data cleaning (TotalCharges is NOT used but still good practice)\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)\n",
    "df.dropna(subset=['TotalCharges'], inplace=True)\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "\n",
    "# ====================================================================\n",
    "# --- NEW: Define the EXACT six features required ---\n",
    "# ====================================================================\n",
    "REQUIRED_FEATURES = [\n",
    "    'Contract', \n",
    "    'tenure', \n",
    "    'InternetService', \n",
    "    'MonthlyCharges', \n",
    "    'OnlineSecurity', \n",
    "    'TechSupport'\n",
    "]\n",
    "TARGET_COLUMN = 'Churn'\n",
    "\n",
    "# Separate features (X) using only the required list, and target (y)\n",
    "X = df[REQUIRED_FEATURES]\n",
    "y = df[TARGET_COLUMN].apply(lambda x: 1 if x == 'Yes' else 0) # Convert 'Yes'/'No' to 1/0\n",
    "\n",
    "print(f\"Data Loaded. Shape: {df.shape}\")\n",
    "print(f\"Features included: {REQUIRED_FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09fd5b58-69f8-44c9-a8c9-7ac6d66acb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (4922, 6)\n",
      "Test set size: (2110, 6)\n",
      "\n",
      "Preprocessing pipeline created using only 6 features.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Identify column types based on the 6 features\n",
    "# 'tenure' and 'MonthlyCharges' are numerical\n",
    "numerical_features = ['tenure', 'MonthlyCharges']\n",
    "# The remaining 4 are categorical\n",
    "categorical_features = ['Contract', 'InternetService', 'OnlineSecurity', 'TechSupport']\n",
    "\n",
    "# Create Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply Standardization to numerical features\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        # Apply One-Hot Encoding to categorical features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nPreprocessing pipeline created using only 6 features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62539e2c-4738-45a2-be75-d6e1e38f51c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forest Model Training on 6 features...\n",
      "Model Training Complete! \n"
     ]
    }
   ],
   "source": [
    "# Define the Model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Create the full pipeline: Preprocessing -> Model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf_classifier)\n",
    "])\n",
    "\n",
    "print(\"Starting Random Forest Model Training on 6 features...\")\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model Training Complete! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33a5bb2-5bcb-4a4c-9727-171f99cc3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy (6 features): 0.7654\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84      1549\n",
      "           1       0.57      0.49      0.53       561\n",
      "\n",
      "    accuracy                           0.77      2110\n",
      "   macro avg       0.70      0.68      0.69      2110\n",
      "weighted avg       0.76      0.77      0.76      2110\n",
      "\n",
      "\n",
      "Model saved successfully to: sklearn_churn_model_6_features.joblib\n"
     ]
    }
   ],
   "source": [
    "# 1. Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# 2. Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Accuracy (6 features): {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 3. Save the model \n",
    "MODEL_PATH = \"sklearn_churn_model_6_features.joblib\" # Changed name to reflect 6 features\n",
    "\n",
    "# Remove existing file if it exists\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    os.remove(MODEL_PATH)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_pipeline, MODEL_PATH)\n",
    "\n",
    "print(f\"\\nModel saved successfully to: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92511144-f14b-4a8f-907c-af7e78a5a6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: sklearn_churn_model_6_features.joblib\n",
      "\n",
      "New Customer Data:\n",
      "         Contract  tenure InternetService  MonthlyCharges OnlineSecurity  \\\n",
      "0  Month-to-month      48     Fiber optic            95.5             No   \n",
      "\n",
      "  TechSupport  \n",
      "0          No  \n",
      "--------------------------------------------------\n",
      "Prediction: WILL NOT CHURN (Prediction = 0)\n",
      "Probability of Churn (P=1): 49.00%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the saved model\n",
    "MODEL_PATH = \"sklearn_churn_model_6_features.joblib\"\n",
    "\n",
    "# Load the saved model pipeline\n",
    "try:\n",
    "    loaded_pipeline = joblib.load(MODEL_PATH)\n",
    "    print(f\"Model loaded successfully from: {MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {MODEL_PATH}. Run Cell 4 first!\")\n",
    "    raise\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. Define the NEW CUSTOMER's data (must only contain the 6 features)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "new_customer_data = {\n",
    "    'Contract': ['Month-to-month'], # High risk\n",
    "    'tenure': [48],                  # Mid-range tenure\n",
    "    'InternetService': ['Fiber optic'], # High risk\n",
    "    'MonthlyCharges': [95.50],        # High\n",
    "    'OnlineSecurity': ['No'],         # High risk\n",
    "    'TechSupport': ['No']             # High risk\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a Pandas DataFrame\n",
    "new_customer_df = pd.DataFrame(new_customer_data)\n",
    "\n",
    "print(\"\\nNew Customer Data:\")\n",
    "print(new_customer_df)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. Make the Prediction\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "prediction = loaded_pipeline.predict(new_customer_df)\n",
    "prediction_proba = loaded_pipeline.predict_proba(new_customer_df)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 3. Interpret and Display the Result\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "churn_status = \"WILL CHURN (Prediction = 1)\" if prediction[0] == 1 else \"WILL NOT CHURN (Prediction = 0)\"\n",
    "churn_probability = prediction_proba[0][1] * 100\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Prediction: {churn_status}\")\n",
    "print(f\"Probability of Churn (P=1): {churn_probability:.2f}%\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29ef1f4-b0c0-4eaf-bd3f-f6ed5d990d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: sklearn_churn_model_6_features.joblib\n",
      "\n",
      "New Customer Data (High Risk Profile):\n",
      "         Contract  tenure InternetService  MonthlyCharges OnlineSecurity  \\\n",
      "0  Month-to-month       2     Fiber optic          105.99             No   \n",
      "\n",
      "  TechSupport  \n",
      "0          No  \n",
      "--------------------------------------------------\n",
      "Prediction: WILL CHURN (Prediction = 1)\n",
      "Probability of Churn (P=1): 81.00%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the saved model\n",
    "MODEL_PATH = \"sklearn_churn_model_6_features.joblib\"\n",
    "\n",
    "# Load the saved model pipeline\n",
    "try:\n",
    "    loaded_pipeline = joblib.load(MODEL_PATH)\n",
    "    print(f\"Model loaded successfully from: {MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {MODEL_PATH}. Run Cell 4 first!\")\n",
    "    raise\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. Define the HIGH-RISK CUSTOMER's data\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "high_risk_customer_data = {\n",
    "    'Contract': ['Month-to-month'], # Highest risk\n",
    "    'tenure': [2],                   # Low tenure = high risk\n",
    "    'InternetService': ['Fiber optic'], # High cost/risk service\n",
    "    'MonthlyCharges': [105.99],       # High charges\n",
    "    'OnlineSecurity': ['No'],         # Lacking security\n",
    "    'TechSupport': ['No']             # Lacking tech support\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a Pandas DataFrame\n",
    "new_customer_df = pd.DataFrame(high_risk_customer_data)\n",
    "\n",
    "print(\"\\nNew Customer Data (High Risk Profile):\")\n",
    "print(new_customer_df)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. Make the Prediction\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "prediction = loaded_pipeline.predict(new_customer_df)\n",
    "prediction_proba = loaded_pipeline.predict_proba(new_customer_df)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 3. Interpret and Display the Result\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "churn_status = \"WILL CHURN (Prediction = 1)\" if prediction[0] == 1 else \"WILL NOT CHURN (Prediction = 0)\"\n",
    "churn_probability = prediction_proba[0][1] * 100\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Prediction: {churn_status}\")\n",
    "print(f\"Probability of Churn (P=1): {churn_probability:.2f}%\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4622c-d00e-4e3f-8a59-ef95bd5530a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
